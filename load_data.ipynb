{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is my personal data folder. Change to your own\n",
    "dir = \"/Users/piromast/Documents/Kaggle/SantanderData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary stuff\n",
    "from pandas import *\n",
    "import numpy as np\n",
    "import os.path\n",
    "set_option(\"display.max_columns\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data (first 1000 rows for now)\n",
    "data=read_csv(os.path.join(dir,'train_ver2.csv'), nrows = 300000, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove nans\n",
    "#data.dropna(axis=1, how='all', inplace=True)\n",
    "#data.dropna(how='any', inplace=True)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import description table (describing the meaning of each column)\n",
    "description = read_csv(os.path.join(dir,'column_description.csv'),encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select product column names and build indeces range\n",
    "column_names = data.columns.values\n",
    "product_names = [(i, s) for i, s in enumerate(column_names) if 'ind_' in s and '_ult1' in s]\n",
    "product_indeces = [e[0] for e in product_names]\n",
    "mInd = min(product_indeces)\n",
    "MInd = max(product_indeces)\n",
    "product_indeces_range = range(mInd,MInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a dataframe only with products\n",
    "product_df = data.iloc[:,product_indeces_range]\n",
    "products_array = product_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving Account                  0.0\n",
       "Guarantees                      1.0\n",
       "Current Accounts           268266.0\n",
       "Derivada Account               16.0\n",
       "Payroll Account             16664.0\n",
       "Junior Account               2150.0\n",
       "MÃ s particular Account       7012.0\n",
       "particular Account             39.0\n",
       "particular Plus Account      1182.0\n",
       "Short-term deposits           960.0\n",
       "Medium-term deposits           99.0\n",
       "Long-term deposits           6347.0\n",
       "e-account                   18213.0\n",
       "Funds                        1018.0\n",
       "Mortgage                       28.0\n",
       "Pensions                      349.0\n",
       "Loans                          36.0\n",
       "Taxes                        5073.0\n",
       "Credit Card                  4928.0\n",
       "Securities                   1395.0\n",
       "Home Account                   13.0\n",
       "Payroll                     10092.0\n",
       "Pensions                    10884.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Series with number of products and use description as indeces\n",
    "desclist=description.iloc[product_indeces_range,1].tolist()\n",
    "num_products = Series(product_df.sum().tolist(),index=desclist)\n",
    "num_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's start scikit-learning\n",
    "import sklearn.preprocessing, sklearn.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dummy variable representation (onehot) for categorical variables\n",
    "# Option 1: user label encoder on each column and onehot encoder on entire dataframe.\n",
    "# This produces an encoding that will probably depend on the number of rows\n",
    "pandas.options.mode.chained_assignment = None\n",
    "\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "oh = sklearn.preprocessing.OneHotEncoder()\n",
    "\n",
    "# Select categorical variables\n",
    "CatVariables = data.iloc[:,(description.iloc[:,2]==2).tolist()]\n",
    "\n",
    "# Store label encoder for each column in a list (to undo encoding)\n",
    "label_encoder_list = []\n",
    "\n",
    "# Apply lable encoder to each column. Then apply onehot encoder to all the data array\n",
    "for i, colname in enumerate(CatVariables):\n",
    "    col = CatVariables[colname].tolist()\n",
    "    \n",
    "    CatVariables.iloc[:,i] = le.fit_transform(col)\n",
    "    label_encoder_list.append(le)\n",
    "    \n",
    "DummyVariables = oh.fit_transform(CatVariables.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Make dummy variable representation (onehot) for categorical variables\n",
    "# # Option 2: apply label encoder and onehot encoding on each column seperately\n",
    "# # I use a pipeline here. All this doesn't work at the moment\n",
    "# \n",
    "# pandas.options.mode.chained_assignment = None\n",
    "# \n",
    "# le = sklearn.preprocessing.LabelEncoder()\n",
    "# oh = sklearn.preprocessing.OneHotEncoder()\n",
    "# encoder = sklearn.pipeline.Pipeline([('LabelEncoder',le),('OnehotEncoder',oh)])\n",
    "# \n",
    "# # Select categorical variables\n",
    "# CatVariables = data.iloc[:,(description.iloc[:,2]==2).tolist()]\n",
    "# encoder_list = []\n",
    "# for i, colname in enumerate(CatVariables):\n",
    "#     le = sklearn.preprocessing.LabelEncoder()\n",
    "#     oh = sklearn.preprocessing.OneHotEncoder()\n",
    "#     #encoder = sklearn.pipeline.Pipeline([('LabelEncoder',le),('OnehotEncoder',oh)])\n",
    "#     col = CatVariables[colname].tolist()\n",
    "# \n",
    "#     CatVariables.iloc[:,i] = le.fit_transform(col)\n",
    "# \n",
    "#     encoder_list.append(le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 3: Use pandas.get_dummies(). This seams to be the best option\n",
    "CatVariables = data.iloc[:,(description.iloc[:,2]==2).tolist()]\n",
    "DummyVariables=pandas.get_dummies(CatVariables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 188)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build feature array including categorical features and continuous data\n",
    "ContinuousVariables = data.iloc[:,(description.iloc[:,2]==1).tolist()].values\n",
    "from sklearn import preprocessing\n",
    "# Impute missing values\n",
    "imputer = sklearn.preprocessing.Imputer(strategy=\"mean\",axis=0)\n",
    "ContinuousVariables = imputer.fit_transform(ContinuousVariables)\n",
    "\n",
    "# Standardize continuous data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "ContinuousVariables = scaler.fit_transform(ContinuousVariables)\n",
    "\n",
    "# Build feature \n",
    "FeatureMatrix=hstack([DummyVariables, ContinuousVariables.astype(np.float64)])\n",
    "\n",
    "FeatureMatrix = imputer.fit_transform(FeatureMatrix)\n",
    "\n",
    "FeatureMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete useless memory intensive stuff\n",
    "del(DummyVariables)\n",
    "del(ContinuousVariables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5, penalty='l1')\n",
    "single_product = products_array[:,12]\n",
    "logreg.fit(FeatureMatrix,single_product)\n",
    "prediction = logreg.predict(FeatureMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n        0.0       0.94      1.00      0.97    281787\\n        1.0       0.00      0.00      0.00     18213\\n\\navg / total       0.88      0.94      0.91    300000\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report(single_product, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.470 (+/-0.000) for {'C': 1}\n",
      "0.470 (+/-0.000) for {'C': 10}\n",
      "0.470 (+/-0.000) for {'C': 100}\n",
      "0.470 (+/-0.000) for {'C': 1000}\n",
      "0.470 (+/-0.000) for {'C': 100000.0}\n",
      "0.470 (+/-0.000) for {'C': 1000000.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97    112733\n",
      "        1.0       0.00      0.00      0.00      7267\n",
      "\n",
      "avg / total       0.88      0.94      0.91    120000\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 1}\n",
      "0.500 (+/-0.000) for {'C': 10}\n",
      "0.500 (+/-0.000) for {'C': 100}\n",
      "0.500 (+/-0.000) for {'C': 1000}\n",
      "0.500 (+/-0.000) for {'C': 100000.0}\n",
      "0.500 (+/-0.000) for {'C': 1000000.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97    112733\n",
      "        1.0       0.00      0.00      0.00      7267\n",
      "\n",
      "avg / total       0.88      0.94      0.91    120000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piromast/Python35VirtualEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(FeatureMatrix, single_product, test_size=0.4, random_state=0)\n",
    "tuned_parameters = [{'C': [1, 10, 100, 1000, 1e5, 1e6]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(logreg, tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
