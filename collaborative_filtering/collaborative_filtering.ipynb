{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_name = 'train_ver2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary stuff\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "processors = 4\n",
    "chunksize=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is my personal data folder. Change to your own\n",
    "#dir = \"/Users/piromast/Documents/Kaggle/SantanderData/\"\n",
    "import os\n",
    "dir = os.getcwd()\n",
    "#train_csv = os.path.join(dir,'train_ver2.csv')\n",
    "client_ids = np.load('client_ids.npy')\n",
    "client_number = client_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_lines =  13647310\n",
      "train_chunks =  1365\n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "def get_dataset_lines():\n",
    "    cmd = \"wc -l \" + csv_name + '.csv'\n",
    "    process = Popen(shlex.split(cmd), stdout=PIPE)\n",
    "    (output, err) = process.communicate()\n",
    "    exit_code = process.wait\n",
    "    train_lines = int(output.split()[0])\n",
    "    return train_lines\n",
    "\n",
    "train_lines = get_dataset_lines()\n",
    "train_chunks = int(np.ceil(float(train_lines)/chunksize))\n",
    "print 'train_lines = ',train_lines\n",
    "print 'train_chunks = ',train_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_reader = pd.read_csv(train_csv, chunksize=1000)\n",
    "#train_reader = pd.read_csv(train_csv, iterator=True, chunksize=1000)\n",
    "#\n",
    "def get_client_ids():\n",
    "    client_ids = np.array([],dtype='int')\n",
    "    for i, chunk in enumerate(train_reader):\n",
    "        client_ids = np.union1d(client_ids,chunk.ncodpers.unique())\n",
    "    return client_ids\n",
    "\n",
    "def create_client_ids_array():\n",
    "    client_ids = get_client_ids()\n",
    "    #client_ids.shape\n",
    "    np.save('client_ids',client_ids)\n",
    "    \n",
    "#create_client_ids_array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class train_chunker(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,chunksize):\n",
    "        self.chunksize     = chunksize\n",
    "        self.csv_path      = os.path.join(dir,'train_ver2.csv')\n",
    "        self.client_ids    = np.load('client_ids.npy')\n",
    "        self.client_number = self.client_ids.shape[0]\n",
    "\n",
    "        self.chunks = int(np.ceil(float(self.client_number)/self.chunksize))\n",
    "        print(str(self.chunks) + ' chunks')\n",
    "        self.reader = pd.read_csv(self.csv_path, chunksize=self.chunksize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0\n",
      "0.059858 seconds process time\n",
      "chunk 10\n",
      "12.360833 seconds process time\n",
      "chunk 20\n",
      "25.15628 seconds process time\n",
      "chunk 30\n",
      "38.177 seconds process time\n",
      "chunk 40\n",
      "51.380304 seconds process time\n",
      "chunk 50\n",
      "64.405444 seconds process time\n",
      "chunk 60\n",
      "78.027614 seconds process time\n",
      "chunk 70\n",
      "91.774762 seconds process time\n",
      "chunk 80\n",
      "105.387984 seconds process time\n",
      "chunk 90\n",
      "119.234759 seconds process time\n",
      "chunk 100\n",
      "132.591157 seconds process time\n",
      "chunk 110\n",
      "145.685445 seconds process time\n",
      "chunk 120\n",
      "159.146393 seconds process time\n",
      "chunk 130\n",
      "172.193065 seconds process time\n",
      "chunk 140\n",
      "185.709338 seconds process time\n",
      "chunk 150\n",
      "199.163887 seconds process time\n",
      "chunk 160\n",
      "212.279586 seconds process time\n",
      "chunk 170\n",
      "225.538692 seconds process time\n",
      "chunk 180\n",
      "238.93178 seconds process time\n",
      "chunk 190\n",
      "252.598802 seconds process time\n",
      "chunk 200\n",
      "265.682728 seconds process time\n",
      "chunk 210\n",
      "279.106672 seconds process time\n",
      "chunk 220\n",
      "292.501515 seconds process time\n",
      "chunk 230\n",
      "306.255064 seconds process time\n",
      "chunk 240\n",
      "320.40904 seconds process time\n",
      "chunk 250\n",
      "334.281847 seconds process time\n",
      "chunk 260\n",
      "347.952973 seconds process time\n",
      "chunk 270\n",
      "361.444657 seconds process time\n",
      "chunk 280\n",
      "374.588367 seconds process time\n",
      "chunk 290\n",
      "387.431796 seconds process time\n",
      "chunk 300\n",
      "400.634879 seconds process time\n",
      "chunk 310\n",
      "414.548228 seconds process time\n",
      "chunk 320\n",
      "429.602154 seconds process time\n",
      "chunk 330\n",
      "444.744716 seconds process time\n",
      "chunk 340\n",
      "459.411072 seconds process time\n",
      "chunk 350\n",
      "473.909684 seconds process time\n",
      "chunk 360\n",
      "489.261215 seconds process time\n",
      "chunk 370\n",
      "503.483248 seconds process time\n",
      "chunk 380\n",
      "517.421951 seconds process time\n",
      "chunk 390\n",
      "530.907356 seconds process time\n",
      "chunk 400\n",
      "544.666342 seconds process time\n",
      "chunk 410\n",
      "558.366785 seconds process time\n",
      "chunk 420\n",
      "572.642116 seconds process time\n",
      "chunk 430\n",
      "586.239877 seconds process time\n",
      "chunk 440\n",
      "600.241402 seconds process time\n",
      "chunk 450\n",
      "615.05855 seconds process time\n",
      "chunk 460\n",
      "629.864696 seconds process time\n",
      "chunk 470\n",
      "644.522263 seconds process time\n",
      "chunk 480\n",
      "659.896607 seconds process time\n",
      "chunk 490\n",
      "675.648132 seconds process time\n",
      "chunk 500\n",
      "690.344299 seconds process time\n",
      "chunk 510\n",
      "705.48333 seconds process time\n",
      "chunk 520\n",
      "720.971064 seconds process time\n",
      "chunk 530\n",
      "737.576865 seconds process time\n",
      "chunk 540\n",
      "753.121806 seconds process time\n",
      "chunk 550\n",
      "767.626822 seconds process time\n",
      "chunk 560\n",
      "782.305118 seconds process time\n",
      "chunk 570\n",
      "796.940525 seconds process time\n",
      "chunk 580\n",
      "810.937886 seconds process time\n",
      "chunk 590\n",
      "825.227821 seconds process time\n",
      "chunk 600\n",
      "839.906597 seconds process time\n",
      "chunk 610\n",
      "855.410614 seconds process time\n",
      "chunk 620\n",
      "869.083908 seconds process time\n",
      "chunk 630\n",
      "883.619828 seconds process time\n",
      "chunk 640\n",
      "898.643673 seconds process time\n",
      "chunk 650\n",
      "912.663921 seconds process time\n",
      "chunk 660\n",
      "927.757851 seconds process time\n",
      "chunk 670\n",
      "942.574507 seconds process time\n",
      "chunk 680\n",
      "956.951772 seconds process time\n",
      "chunk 690\n",
      "971.835237 seconds process time\n",
      "chunk 700\n",
      "986.754536 seconds process time\n",
      "chunk 710\n",
      "1001.83872 seconds process time\n",
      "chunk 720\n",
      "1016.400249 seconds process time\n",
      "chunk 730\n",
      "1031.372532 seconds process time\n",
      "chunk 740\n",
      "1046.244681 seconds process time\n",
      "chunk 750\n",
      "1061.591669 seconds process time\n",
      "chunk 760\n",
      "1077.049671 seconds process time\n",
      "chunk 770\n",
      "1092.980648 seconds process time\n",
      "chunk 780\n",
      "1108.50915 seconds process time\n",
      "chunk 790\n",
      "1123.721956 seconds process time\n",
      "chunk 800\n",
      "1139.296209 seconds process time\n",
      "chunk 810\n",
      "1154.926997 seconds process time\n",
      "chunk 820\n",
      "1170.468737 seconds process time\n",
      "chunk 830\n",
      "1186.151733 seconds process time\n",
      "chunk 840\n",
      "1202.124401 seconds process time\n",
      "chunk 850\n",
      "1218.308392 seconds process time\n",
      "chunk 860\n",
      "1234.900855 seconds process time\n",
      "chunk 870\n",
      "1250.142993 seconds process time\n",
      "chunk 880\n",
      "1264.604033 seconds process time\n",
      "chunk 890\n",
      "1281.324602 seconds process time\n",
      "chunk 900\n",
      "1298.430712 seconds process time\n",
      "chunk 910\n",
      "1314.846126 seconds process time\n",
      "chunk 920\n",
      "1330.655988 seconds process time\n",
      "chunk 930\n",
      "1346.007617 seconds process time\n",
      "chunk 940\n",
      "1362.568965 seconds process time\n",
      "chunk 950\n",
      "1378.533389 seconds process time\n",
      "chunk 960\n",
      "1394.263182 seconds process time\n",
      "chunk 970\n",
      "1409.581812 seconds process time\n",
      "chunk 980\n",
      "1425.736591 seconds process time\n",
      "chunk 990\n",
      "1443.082095 seconds process time\n",
      "chunk 1000\n",
      "1460.615615 seconds process time\n",
      "chunk 1010\n",
      "1477.779384 seconds process time\n",
      "chunk 1020\n",
      "1494.60436 seconds process time\n",
      "chunk 1030\n",
      "1511.350079 seconds process time\n",
      "chunk 1040\n",
      "1528.797014 seconds process time\n",
      "chunk 1050\n",
      "1545.215352 seconds process time\n",
      "chunk 1060\n",
      "1561.414836 seconds process time\n",
      "chunk 1070\n",
      "1577.722342 seconds process time\n",
      "chunk 1080\n",
      "1594.939528 seconds process time\n",
      "chunk 1090\n",
      "1611.513977 seconds process time\n",
      "chunk 1100\n",
      "1628.867735 seconds process time\n",
      "chunk 1110\n",
      "1642.623449 seconds process time\n",
      "chunk 1120\n",
      "1654.788997 seconds process time\n",
      "chunk 1130\n",
      "1666.879261 seconds process time\n",
      "chunk 1140\n",
      "1678.8987 seconds process time\n",
      "chunk 1150\n",
      "1694.292681 seconds process time\n",
      "chunk 1160\n",
      "1709.49488 seconds process time\n",
      "chunk 1170\n",
      "1723.746874 seconds process time\n",
      "chunk 1180\n",
      "1738.892796 seconds process time\n",
      "chunk 1190\n",
      "1752.921037 seconds process time\n",
      "chunk 1200\n",
      "1766.653083 seconds process time\n",
      "chunk 1210\n",
      "1779.439426 seconds process time\n",
      "chunk 1220\n",
      "1791.1621 seconds process time\n",
      "chunk 1230\n",
      "1802.947923 seconds process time\n",
      "chunk 1240\n",
      "1820.591551 seconds process time\n",
      "chunk 1250\n",
      "1842.459241 seconds process time\n",
      "chunk 1260\n",
      "1863.326766 seconds process time\n",
      "chunk 1270\n",
      "1884.091559 seconds process time\n",
      "chunk 1280\n",
      "1905.325397 seconds process time\n",
      "chunk 1290\n",
      "1926.087496 seconds process time\n",
      "chunk 1300\n",
      "1948.377836 seconds process time\n",
      "chunk 1310\n",
      "1969.940483 seconds process time\n",
      "chunk 1320\n",
      "1992.75388 seconds process time\n",
      "chunk 1330\n",
      "2013.251312 seconds process time\n",
      "chunk 1340\n",
      "2035.727422 seconds process time\n",
      "chunk 1350\n",
      "2057.14677 seconds process time\n",
      "chunk 1360\n",
      "2079.527016 seconds process time\n"
     ]
    }
   ],
   "source": [
    "train_reader = pd.read_csv(csv_name, chunksize=chunksize)\n",
    "\n",
    "\n",
    "def find_client_index(ncodpers):\n",
    "    return np.argwhere(client_ids == ncodpers)\n",
    "\n",
    "def create_dataset_client_index_array():\n",
    "\n",
    "    train_data_client_indices = np.array([],dtype='int')\n",
    "    #train_data_client_indices = np.full((client_number),np.NaN,dtype='int')\n",
    "    j = 0\n",
    "\n",
    "    # measure process time\n",
    "    import time\n",
    "    t0 = time.clock()\n",
    "\n",
    "    for i, chunk in enumerate(train_reader):\n",
    "        if i%100==0:\n",
    "            proc_time = time.clock() - t0\n",
    "            print('chunk ' + str(i) + ' from ' str(train_chunks) + '. (' + str(proc_time) + ' secs)')\n",
    "\n",
    "        chunk_ncodpers = chunk.ncodpers\n",
    "        #print chunk_ncodpers[0]\n",
    "        stdout = Parallel(n_jobs=processors)\\\n",
    "        (delayed(find_client_index)(ncodpers) for ncodpers in chunk_ncodpers)\n",
    "\n",
    "        chunk_indices = np.full((chunksize),np.NaN)\n",
    "        for i, indice in enumerate(stdout):\n",
    "            chunk_indices[i]= indice\n",
    "\n",
    "        train_data_client_indices = np.concatenate((train_data_client_indices, chunk_indices))\n",
    "        #    train_data_client_indices[i*chunksize:(i+1)*chunksize] = chunk_indices\n",
    "\n",
    "    np.save(csv_name + '__client_indices',train_data_client_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client_ids[540143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(stdout[:])[0]\n",
    "print stdout[0][0][0]\n",
    "print stdout[:][0][0]\n",
    "print stdout[0][:][0]\n",
    "print stdout[0][0][:]\n",
    "chunk_indices = np.full((chunksize),np.NaN)\n",
    "for i, indice in enumerate(stdout):\n",
    "    chunk_indices[i]= indice\n",
    "print chunk_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary stuff\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_reader = pd.read_csv(train_csv, chunksize=chunksize)\n",
    "client_id = client_ids[0]\n",
    "client_matrix = pd.DataFrame()\n",
    "for i, chunk in enumerate(train_reader):\n",
    "    client_lines = chunk.ncodpers == client_id\n",
    "    #print client_lines == True\n",
    "    client_matrix = client_matrix.append(chunk.ix[client_lines])    \n",
    "    isinchunk = np.sum(client_lines)\n",
    "\n",
    "#    if isinchunk != 0.0:\n",
    "#        print i, isinchunk,len(client_matrix)\n",
    "#        #print chunk.ix[client_lines]\n",
    "#        print client_matrix\n",
    "#        raw_input()\n",
    "        #break\n",
    "client_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(train_reader):\n",
    "    pass\n",
    "print i\n",
    "#    print(chunk.ncodpers.unique().shape)\n",
    "\n",
    "#data=train_df.get_chunk()\n",
    "#data.ncodpers.unique()\n",
    "#for chunk_df in train_df:\n",
    "#    chunk_data = chunk_df.get_chunk()\n",
    "#    print chunk_data.shape\n",
    "#read\n",
    "#data.ncodpers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import description table (describing the meaning of each column)\n",
    "description = read_csv(os.path.join(dir,'column_description.csv'),encoding = 'latin1')\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select product column names and build indeces range\n",
    "column_names = data.columns.values\n",
    "product_names = [(i, s) for i, s in enumerate(column_names) if 'ind_' in s and '_ult1' in s]\n",
    "product_indeces = [e[0] for e in product_names]\n",
    "mInd = min(product_indeces)\n",
    "MInd = max(product_indeces)\n",
    "product_indeces_range = range(mInd,MInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a dataframe only with products\n",
    "product_df = data.iloc[:,product_indeces_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a Series with number of products and use description as indeces\n",
    "desclist=description.iloc[product_indeces_range,1].tolist()\n",
    "num_products = Series(product_df.sum().tolist(),index=desclist)\n",
    "num_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
